{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AiFinal2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oltmeal20/Adapter-Project/blob/master/Copy_of_AiFinal2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4vrR4d-Euhc"
      },
      "source": [
        "# German Traffic Sign Classifier\n",
        "### By Luke Oltmanns & Ryan Peerenboom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieLlz9ahs467"
      },
      "source": [
        "# Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tCdptws5RL"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import csv\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage import data as skimage_data\n",
        "from skimage import transform\n",
        "from skimage.color import rgb2gray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dLRCRqZs5fr"
      },
      "source": [
        "#paths to data\n",
        "root = \"./drive/MyDrive/Dataset/\"\n",
        "trainPath = \"./drive/MyDrive/Dataset/Train.csv\"\n",
        "testPath = \"./drive/MyDrive/Dataset/Test.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoQbCaNCs5sW"
      },
      "source": [
        "columns = [\"Width\", \"Height\", \"Roi.X1\", \"Roi.Y1\", \"Roi.X2\", \"Roi.Y2\", \"ClassId\", \"Path\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy2XkQdas6fI"
      },
      "source": [
        "#method for loading training data\n",
        "def loadDataset(path):\n",
        "    images_histogram_equalized = []\n",
        "    images = []\n",
        "    classes = []\n",
        "    data = pd.read_csv(path)\n",
        "    data = data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # loop to pull images from csv one row at a time\n",
        "    for i,row in data.iterrows():\n",
        "        img_path = row['Path']\n",
        "        img_class = row['ClassId']\n",
        "\n",
        "        img = os.path.join(root,img_path)\n",
        "        img = cv2.imread(img)\n",
        "\n",
        "        # bypasses any image not loaded to avoid erros\n",
        "        if type(img) is np.ndarray:\n",
        "            if img.size == 0:\n",
        "                continue\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        # resize image to disired size\n",
        "        img_resize = cv2.resize(img,(32,32),3) #resizes each img to size 32*32*3\n",
        "\n",
        "        #split and perform histogram equalization to enhance image contrast\n",
        "        R, G, B = cv2.split((img_resize))\n",
        "\n",
        "        img_r = cv2.equalizeHist(R)\n",
        "        img_g = cv2.equalizeHist(G)\n",
        "        img_b = cv2.equalizeHist(B)\n",
        "\n",
        "        new_image = cv2.merge((img_r, img_g, img_b))\n",
        "\n",
        "        # put data into numpy arrays\n",
        "        if i>0 and i%1000 == 0:\n",
        "            print(\"loaded: \",i,\" images\")\n",
        "        images.append(img_resize)\n",
        "        images_histogram_equalized.append(new_image)\n",
        "        classes.append(img_class)\n",
        "\n",
        "    # put data into numpy arrays\n",
        "    imgs = np.array(images)\n",
        "    imgs_hist = np.array(images_histogram_equalized)\n",
        "    labels = np.array(classes)\n",
        "    \n",
        "    return imgs, imgs_hist, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcrmetoZs8Hx"
      },
      "source": [
        "#use crated 'loadDataset()' methods to retrieve training images and labels\n",
        "X_train, y_train = loadDataset(trainPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzqrCw0fHQES"
      },
      "source": [
        "#use crated 'loadDataset()' methods to retrieve testing images and labels\n",
        "X_test, y_test = loadDataset(testPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXdi1r7Us8UB"
      },
      "source": [
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_test: \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLjSdFpds8ld"
      },
      "source": [
        "#Normalize pixel values between 0 and 1\n",
        "X_train, X_train_hist, X_test, X_test_hist= X_train/255.0, X_train_hist/255.0, X_test/255.0, X_test_hist/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNNweHmrtrOD"
      },
      "source": [
        "### Displaying the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhaeZbp8twgg"
      },
      "source": [
        "#verify dataset\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(y_train[i])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tCPtK_-tww1"
      },
      "source": [
        "#verify training data as a bar graph\n",
        "n_classes = max(y_test) - min(y_test) + 1\n",
        "classes = range(n_classes)\n",
        "counts = []\n",
        "\n",
        "for sign_code in range(n_classes):\n",
        "    image_list = list(np.where(y_train == sign_code)[0])\n",
        "    counts += [len(image_list)]\n",
        "    \n",
        "plt.figure(figsize=(15,5)) \n",
        "plt.bar(classes, counts, width=0.7, align='center')\n",
        "plt.ylabel('Number of Examples')\n",
        "plt.xlabel('Class Index')\n",
        "plt.xticks(np.arange(0, 43, 1.0))\n",
        "plt.title(\"Class Distribution of Training Set\")\n",
        "plt.ylim([0,4000])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB1ihQ0LtxBl"
      },
      "source": [
        "#verify testing data as a bar graph\n",
        "n_classes = max(y_test) - min(y_test) + 1\n",
        "classes = range(n_classes)\n",
        "counts = []\n",
        "\n",
        "for sign_code in range(n_classes):\n",
        "    image_list = list(np.where(y_test == sign_code)[0])\n",
        "    counts += [len(image_list)]\n",
        "    \n",
        "plt.figure(figsize=(15,5)) \n",
        "plt.bar(classes, counts, width=0.7, align='center')\n",
        "plt.ylabel('Number of Examples')\n",
        "plt.xlabel('Class Index')\n",
        "plt.xticks(np.arange(0, 43, 1.0))\n",
        "plt.title(\"Class Distribution of Testing Set\")\n",
        "plt.ylim([0,4000])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdNiBusit73y"
      },
      "source": [
        "# Building Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc-8z2Brsp0C"
      },
      "source": [
        "### CNN ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eYZY3i1t8yL"
      },
      "source": [
        "#create convolutional Neural Network (CNN) with base \"relu\"\n",
        "CNNModelRelu = models.Sequential()\n",
        "CNNModelRelu.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "CNNModelRelu.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelRelu.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CNNModelRelu.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelRelu.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CNNModelRelu.add(layers.Dropout(0.2))\n",
        "\n",
        "#add dense layers\n",
        "CNNModelRelu.add(layers.Flatten())\n",
        "CNNModelRelu.add(layers.Dense(64, activation='relu'))\n",
        "CNNModelRelu.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#compile and train the CNNModelRelu\n",
        "CNNModelRelu.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "CNNHistoryRelu = CNNModelRelu.fit(X_train_hist, y_train, epochs=10, validation_data=(X_test_hist, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7g60431suT1"
      },
      "source": [
        "### CNN Tanh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky3fDC6yt8_9"
      },
      "source": [
        "#create convolutional Neural Network (CNN) with base \"tanh\"\n",
        "CNNModelTanh= models.Sequential()\n",
        "CNNModelTanh.add(layers.Conv2D(32, (3, 3), activation='tanh', input_shape=(32, 32, 3)))\n",
        "CNNModelTanh.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelTanh.add(layers.Conv2D(64, (3, 3), activation='tanh'))\n",
        "CNNModelTanh.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelTanh.add(layers.Conv2D(64, (3, 3), activation='tanh'))\n",
        "CNNModelTanh.add(layers.Dropout(0.2))\n",
        "\n",
        "#add dense layers\n",
        "CNNModelTanh.add(layers.Flatten())\n",
        "CNNModelTanh.add(layers.Dense(64, activation='tanh'))\n",
        "CNNModelTanh.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#compile and train the CNNModelTanh\n",
        "CNNModelTanh.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "CNNHistoryTanh= CNNModelTanh.fit(X_train_hist, y_train, epochs=10, validation_data=(X_test_hist, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44wOBz0Es5PJ"
      },
      "source": [
        "### CNN Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QDLMSDUt9NH"
      },
      "source": [
        "#create convolutional Neural Network (CNN) with base \"sigmoid\"\n",
        "CNNModelSig= models.Sequential()\n",
        "CNNModelSig.add(layers.Conv2D(32, (3, 3), activation='sigmoid', input_shape=(32, 32, 3)))\n",
        "CNNModelSig.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelSig.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n",
        "CNNModelSig.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelSig.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n",
        "CNNModelSig.add(layers.Dropout(0.2))\n",
        "\n",
        "#add dense layers\n",
        "CNNModelSig.add(layers.Flatten())\n",
        "CNNModelSig.add(layers.Dense(64, activation='sigmoid'))\n",
        "CNNModelSig.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#compile and train the CNNModelSig\n",
        "CNNModelSig.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "CNNHistorySig = CNNModelSig.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h21hsPAns8lN"
      },
      "source": [
        "### CNN Cross Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne6r35nytApX"
      },
      "source": [
        "#create convolutional Neural Network (CNN) with cross activations\n",
        "CNNModelX= models.Sequential()\n",
        "CNNModelX.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "CNNModelX.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelX.add(layers.Conv2D(64, (3, 3), activation='tanh'))\n",
        "CNNModelX.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelX.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n",
        "CNNModelX.add(layers.Dropout(0.1))\n",
        "\n",
        "#add dense layers\n",
        "CNNModelX.add(layers.Flatten())\n",
        "CNNModelX.add(layers.Dense(64, activation='relu'))\n",
        "CNNModelX.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#compile and train the CNNModelX\n",
        "CNNModelX.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "CNNHistoryX= CNNModelX.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ytaLQgAtFTB"
      },
      "source": [
        "### CNN Random Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrM4kbmDtFmw"
      },
      "source": [
        "#create random convolutional Neural Network (CNN)\n",
        "CNNModelRand= models.Sequential()\n",
        "CNNModelRand.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
        "CNNModelRand.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelRand.add(layers.Conv2D(48, (5, 5), activation='relu'))\n",
        "CNNModelRand.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelRand.add(layers.Dropout(0.2))\n",
        "\n",
        "#add dense layers\n",
        "CNNModelRand.add(layers.Flatten())\n",
        "CNNModelRand.add(layers.Dense(128, activation='relu'))\n",
        "CNNModelRand.add(layers.Dense(64, activation='relu'))\n",
        "CNNModelRand.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#compile and train the CNNModelRand\n",
        "CNNModelRand.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "CNNHistoryRand= CNNModelRand.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HvennJWtF2K"
      },
      "source": [
        "### CNN Random Layers Two"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s94PYUeztGAU"
      },
      "source": [
        "#create second random convolutional Neural Network (CNN)\n",
        "CNNModelRandTwo= models.Sequential()\n",
        "CNNModelRandTwo.add(layers.Conv2D(32, (3, 3), activation='tanh', input_shape=(32, 32, 3)))\n",
        "CNNModelRandTwo.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNModelRandTwo.add(layers.Conv2D(128, (2, 2), activation='relu'))\n",
        "CNNModelRandTwo.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
        "CNNModelRandTwo.add(layers.MaxPooling2D((3, 3)))\n",
        "CNNModelRandTwo.add(layers.Dropout(0.4))\n",
        "\n",
        "#add dense layers\n",
        "CNNModelRandTwo.add(layers.Flatten())\n",
        "CNNModelRandTwo.add(layers.Dense(512, activation='relu'))\n",
        "CNNModelRandTwo.add(layers.Dense(256, activation='tanh'))\n",
        "CNNModelRandTwo.add(layers.Dropout(0.2))\n",
        "CNNModelRandTwo.add(layers.Dense(512, activation='relu'))\n",
        "CNNModelRandTwo.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#compile and train the CNNModelRandTwo\n",
        "CNNModelRandTwo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "CNNHistoryRandTwo= CNNModelRandTwo.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFPITNHQtGS0"
      },
      "source": [
        "### Simple Dense NN 0 hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WTyn39wtGdM"
      },
      "source": [
        "#simple dense neural network with 0 hidden layers of ReLU\n",
        "SDNNModelZero = models.Sequential()\n",
        "SDNNModelZero.add(layers.Flatten())\n",
        "SDNNModelZero.add(layers.Dense(43, activation='softmax'))\n",
        "SDNNModelZero.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "SDNNHistoryZero= SDNNModelZero.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzbvx_dgtGnz"
      },
      "source": [
        "### Simple Dense NN 5 hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk69FMBTtGwQ"
      },
      "source": [
        "#simple dense neural network with 5 hidden layers of ReLU\n",
        "SDNNModelFiveRelu = models.Sequential()\n",
        "SDNNModelFiveRelu.add(layers.Flatten())\n",
        "SDNNModelFiveRelu.add(layers.Dense(1024, activation='relu'))\n",
        "SDNNModelFiveRelu.add(layers.Dense(512, activation='relu'))\n",
        "SDNNModelFiveRelu.add(layers.Dense(256, activation='relu'))\n",
        "SDNNModelFiveRelu.add(layers.Dense(128, activation='relu'))\n",
        "SDNNModelFiveRelu.add(layers.Dense(64, activation='relu'))\n",
        "SDNNModelFiveRelu.add(layers.Dense(43, activation='softmax'))\n",
        "SDNNModelFiveRelu.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "SDNNHistoryFiveRelu= SDNNModelFiveRelu.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU6P5N1dOBc6"
      },
      "source": [
        "### CNN Best Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "537vtOkDOA_n"
      },
      "source": [
        "#create convolutional neural network with best result\n",
        "CNNModelBest= models.Sequential()\n",
        "CNNModelBest.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
        "CNNModelBest.add(layers.BatchNormalization())\n",
        "CNNModelBest.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "CNNModelBest.add(layers.Conv2D(48, (5, 5), activation='relu'))\n",
        "CNNModelBest.add(layers.BatchNormalization())\n",
        "CNNModelBest.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "#add dense layers\n",
        "CNNModelBest.add(layers.Flatten())\n",
        "CNNModelBest.add(layers.Dense(120, activation='relu'))\n",
        "CNNModelBest.add(layers.Dropout(0.2))\n",
        "CNNModelBest.add(layers.Dense(84, activation='relu'))\n",
        "CNNModelBest.add(layers.Dropout(0.1))\n",
        "CNNModelBest.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#compile and train the CNNModelBest\n",
        "CNNModelBest.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "CNNHistoryBest= CNNModelBest.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTzQF4Z7uNtB"
      },
      "source": [
        "# Testing the Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LawpoxC7t4bx"
      },
      "source": [
        "### Standard CNN Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jy-LF5xt-ut"
      },
      "source": [
        "#display traditional CNN models' accuracies\n",
        "plt.plot(CNNHistoryRelu.history['acc'], label='CNN ReLU accuracy')\n",
        "plt.plot(CNNHistoryRelu.history['val_acc'], label='CNN ReLU val_accuracy')\n",
        "\n",
        "plt.plot(CNNHistoryTanh.history['acc'], label='CNN Tanh accuracy')\n",
        "plt.plot(CNNHistoryTanh.history['val_acc'], label='CNN Tanh val_accuracy')\n",
        "\n",
        "plt.plot(CNNHistorySig.history['acc'], label='CNN Sigmoid accuracy')\n",
        "plt.plot(CNNHistorySig.history['val_acc'], label='CNN Sigmoid val_accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aHcqNpcuTfy"
      },
      "source": [
        "#display traditional CNN models' loss\n",
        "plt.plot(CNNHistoryRelu.history['loss'], label='CNN ReLU loss')\n",
        "plt.plot(CNNHistoryRelu.history['val_loss'], label='CNN ReLU val_loss')\n",
        "\n",
        "plt.plot(CNNHistoryTanh.history['loss'], label='CNN Tanh loss')\n",
        "plt.plot(CNNHistoryTanh.history['val_loss'], label='CNN Tanh val_loss')\n",
        "\n",
        "plt.plot(CNNHistorySig.history['loss'], label='CNN Sigmoid loss')\n",
        "plt.plot(CNNHistorySig.history['val_loss'], label='CNN Sigmoid val_loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 0.5])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCNHm_nouTr_"
      },
      "source": [
        "#evaluate traditional CNN models\n",
        "relu_test_loss, relu_test_acc = CNNModelRelu.evaluate(X_test, y_test, verbose = 2)\n",
        "print(\"The ReLU test accuracy is: \" + str(relu_test_acc))\n",
        "print(\"The ReLU test loss is: \" + str(relu_test_loss))\n",
        "\n",
        "tanh_test_loss, tanh_test_acc = CNNModelTanh.evaluate(X_test, y_test, verbose = 2)\n",
        "print(\"The Tanh test accuracy is: \" + str(tanh_test_acc))\n",
        "print(\"The Tanh test loss is: \" + str(tanh_test_loss))\n",
        "\n",
        "sig_test_loss, sig_test_acc = CNNModelSig.evaluate(X_test, y_test, verbose = 2)\n",
        "print(\"The Sigmoid test accuracy is: \" + str(sig_test_acc))\n",
        "print(\"The Sigmoid test loss is: \" + str(sig_test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm4MUA0mt_Rb"
      },
      "source": [
        "### Exotic CNN Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVqR2OcCuFO7"
      },
      "source": [
        "#display exotic CNN models' accuracies\n",
        "plt.plot(CNNHistoryX.history['acc'], label='CNN Cross accuracy')\n",
        "plt.plot(CNNHistoryX.history['val_acc'], label='CNN Cross val_accuracy')\n",
        "\n",
        "plt.plot(CNNHistoryRand.history['acc'], label='CNN Random accuracy')\n",
        "plt.plot(CNNHistoryRand.history['val_acc'], label='CNN Random val_accuracy')\n",
        "\n",
        "plt.plot(CNNHistoryRandTwo.history['acc'], label='CNN Random Two accuracy')\n",
        "plt.plot(CNNHistoryRandTwo.history['val_acc'], label='CNN Random Two val_accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dBzZ6AiuyhE"
      },
      "source": [
        "#evaluate exotic CNN models\n",
        "X_test_loss, X_test_acc = CNNModelX.evaluate(X_test, y_test, verbose = 2)\n",
        "print(\"The Cross test accuracy is: \" + str(X_test_acc))\n",
        "\n",
        "Rand_test_loss, Rand_test_acc = CNNModelRand.evaluate(X_test, y_test, verbose = 2)\n",
        "print(\"The Random test accuracy is: \" + str(Rand_test_acc))\n",
        "\n",
        "RandTwo_test_loss, RandTwo_test_acc = CNNModelRandTwo.evaluate(X_test, y_test, verbose = 2)\n",
        "print(\"The Second Random test accuracy is: \" + str(sig_test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfsDBgyUuFjc"
      },
      "source": [
        "### Simple Dense NN Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx8bzUILu23C"
      },
      "source": [
        "#display SDNN models' accuracies\n",
        "plt.plot(SDNNHistoryZero.history['acc'], label='SDNN Zero accuracy')\n",
        "plt.plot(SDNNHistoryZero.history['val_acc'], label='SDNN Zero val_accuracy')\n",
        "\n",
        "plt.plot(SDNNHistoryFiveRelu.history['acc'], label='SDNN Five accuracy')\n",
        "plt.plot(SDNNHistoryFiveRelu.history['val_acc'], label='SDNN Five val_accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RXIuSiMu3Ag"
      },
      "source": [
        "#evaluate exotic CNN models\n",
        "Zero_test_loss, Zero_test_acc = SDNNModelZero.evaluate(X_test, y_test, verbose = 2)\n",
        "print(\"The zero hidden layer test accuracy is: \" + str(Zero_test_acc))\n",
        "\n",
        "Five_test_loss, Rand_test_acc = SDNNModelFiveRelu.evaluate(X_test, y_test, verbose = 2)\n",
        "print(\"The five hidden layer test accuracy is: \" + str(Rand_test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apjg5BDROzAa"
      },
      "source": [
        "### Best Result Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDYIp9ehOzTE"
      },
      "source": [
        "#display 'Best' model accuracies\n",
        "plt.plot(CNNHistoryBest.history['acc'], label='CNN Best Result accuracy')\n",
        "plt.plot(CNNHistoryBest.history['val_acc'], label='CNN Best Result val_accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaqxbZpiPdDS"
      },
      "source": [
        "#display 'Best' model loss\n",
        "plt.plot(CNNHistoryBest.history['loss'], label='CNN Best Result loss')\n",
        "plt.plot(CNNHistoryBest.history['val_loss'], label='CNN Best Result val_loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 0.5])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efc7JZtFPka6"
      },
      "source": [
        "#evaluate 'Best' model\n",
        "best_test_loss, best_test_acc = CNNModelBest.evaluate(X_test, y_test, verbose = 2)\n",
        "print(\"The Best Result test accuracy is: \" + str(best_test_acc))\n",
        "print(\"The Best Result test loss is: \" + str(best_test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXMsqAaPu8dv"
      },
      "source": [
        "### All Model Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKAWObbFu7uJ"
      },
      "source": [
        "#display all models' accuracies\n",
        "plt.plot(CNNHistoryRelu.history['acc'], label='CNN ReLU accuracy')\n",
        "plt.plot(CNNHistoryTanh.history['acc'], label='CNN Tanh accuracy')\n",
        "plt.plot(CNNHistorySig.history['acc'], label='CNN Sigmoid accuracy')\n",
        "plt.plot(CNNHistoryX.history['acc'], label='CNN Cross accuracy')\n",
        "plt.plot(CNNHistoryRand.history['acc'], label='CNN Random accuracy')\n",
        "plt.plot(CNNHistoryRandTwo.history['acc'], label='CNN Random Two accuracy')\n",
        "plt.plot(SDNNHistoryZero.history['acc'], label='SDNN Zero accuracy')\n",
        "plt.plot(SDNNHistoryFiveRelu.history['acc'], label='SDNN Five accuracy')\n",
        "plt.plot(CNNHistoryBest.history['acc'], label='CNN Best Result accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9DgBj-8uaOY"
      },
      "source": [
        "## Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2HbI4t-ukWJ"
      },
      "source": [
        "#verify that our model is accurate by showing that an image from \n",
        "#our test data matches a predicted image from our model evaluation\n",
        "probability_model = tf.keras.Sequential([CNNModelBest, tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(X_test)\n",
        "predictions[0]\n",
        "np.argmax(predictions[0])\n",
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm1WCsU-yWYi"
      },
      "source": [
        "## Verify Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUXLOoMBvNS7"
      },
      "source": [
        "#array of labels (corresponds with the bar graphs dispayed above)\n",
        "class_names = ['0','1','2','3','4','5','6','7','8','9',\n",
        "               '10','11','12','13','14','15','16','17','18','19',\n",
        "               '20','21','22','23','24','25','26','27','28','29',\n",
        "               '30','31','32','33','34','35','36','37','38','39',\n",
        "               '40','41','42']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzjph3JxyW5Z"
      },
      "source": [
        "#method for displaying images\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyW9PusvvTlQ"
      },
      "source": [
        "#method for displaying graph of image classification accuracy\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  true_label = true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(43))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(43), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 0.1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6JLkN3yyXFZ"
      },
      "source": [
        "#display a single image and visual result\n",
        "i = 0\n",
        "plt.figure(figsize=(30,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], y_test, X_test)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i], y_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQHRE1dHyXMU"
      },
      "source": [
        "#display a single image and visual result\n",
        "i = 12\n",
        "plt.figure(figsize=(30,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], y_test, X_test)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i], y_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxtcA-s6yXTe"
      },
      "source": [
        "#display a multiple images and visual result of those images\n",
        "num_rows = 15\n",
        "num_cols = 1\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*20*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], y_test, X_test)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], y_test)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}